{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":30787,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2024-11-09T11:01:17.793780Z","iopub.execute_input":"2024-11-09T11:01:17.794295Z","iopub.status.idle":"2024-11-09T11:01:17.801716Z","shell.execute_reply.started":"2024-11-09T11:01:17.794254Z","shell.execute_reply":"2024-11-09T11:01:17.800632Z"}},"outputs":[],"execution_count":17},{"cell_type":"code","source":"!pip install -U accelerate\n!pip install -U transformers\n!pip install datasets\n!pip install -q -U google-generativeai","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-09T11:01:17.803656Z","iopub.execute_input":"2024-11-09T11:01:17.804528Z","iopub.status.idle":"2024-11-09T11:02:04.761085Z","shell.execute_reply.started":"2024-11-09T11:01:17.804484Z","shell.execute_reply":"2024-11-09T11:02:04.759784Z"}},"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/pty.py:89: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n  pid, fd = os.forkpty()\n","output_type":"stream"},{"name":"stdout","text":"Requirement already satisfied: accelerate in /opt/conda/lib/python3.10/site-packages (1.1.1)\nRequirement already satisfied: huggingface-hub>=0.21.0 in /opt/conda/lib/python3.10/site-packages (from accelerate) (0.25.1)\nRequirement already satisfied: numpy<3.0.0,>=1.17 in /opt/conda/lib/python3.10/site-packages (from accelerate) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from accelerate) (21.3)\nRequirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from accelerate) (5.9.3)\nRequirement already satisfied: pyyaml in /opt/conda/lib/python3.10/site-packages (from accelerate) (6.0.2)\nRequirement already satisfied: safetensors>=0.4.3 in /opt/conda/lib/python3.10/site-packages (from accelerate) (0.4.5)\nRequirement already satisfied: torch>=1.10.0 in /opt/conda/lib/python3.10/site-packages (from accelerate) (2.4.0)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.21.0->accelerate) (3.15.1)\nRequirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.21.0->accelerate) (2024.6.1)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.21.0->accelerate) (2.32.3)\nRequirement already satisfied: tqdm>=4.42.1 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.21.0->accelerate) (4.66.4)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.21.0->accelerate) (4.12.2)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->accelerate) (3.1.2)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (1.13.3)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (3.3)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (3.1.4)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.5)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.21.0->accelerate) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.21.0->accelerate) (3.7)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.21.0->accelerate) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.21.0->accelerate) (2024.8.30)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\nRequirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (4.46.2)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers) (3.15.1)\nRequirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.25.1)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers) (21.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (6.0.2)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (2024.5.15)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers) (2.32.3)\nRequirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.4.5)\nRequirement already satisfied: tokenizers<0.21,>=0.20 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.20.0)\nRequirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers) (4.66.4)\nRequirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2024.6.1)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.12.2)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->transformers) (3.1.2)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.7)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (2024.8.30)\nRequirement already satisfied: datasets in /opt/conda/lib/python3.10/site-packages (3.0.1)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from datasets) (3.15.1)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from datasets) (1.26.4)\nRequirement already satisfied: pyarrow>=15.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (16.1.0)\nRequirement already satisfied: dill<0.3.9,>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (0.3.8)\nRequirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from datasets) (2.2.2)\nRequirement already satisfied: requests>=2.32.2 in /opt/conda/lib/python3.10/site-packages (from datasets) (2.32.3)\nRequirement already satisfied: tqdm>=4.66.3 in /opt/conda/lib/python3.10/site-packages (from datasets) (4.66.4)\nRequirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from datasets) (3.4.1)\nRequirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from datasets) (0.70.16)\nRequirement already satisfied: fsspec<=2024.6.1,>=2023.1.0 in /opt/conda/lib/python3.10/site-packages (from fsspec[http]<=2024.6.1,>=2023.1.0->datasets) (2024.6.1)\nRequirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets) (3.9.5)\nRequirement already satisfied: huggingface-hub>=0.22.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (0.25.1)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from datasets) (21.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from datasets) (6.0.2)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.3.1)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (23.2.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.4.1)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (6.0.5)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.9.4)\nRequirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (4.0.3)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.22.0->datasets) (4.12.2)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->datasets) (3.1.2)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests>=2.32.2->datasets) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.32.2->datasets) (3.7)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.32.2->datasets) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.32.2->datasets) (2024.8.30)\nRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2024.1)\nRequirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2024.1)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n","output_type":"stream"}],"execution_count":18},{"cell_type":"code","source":"import os\nos.environ['GOOGLE_API_KEY'] = 'AIzaSyCZUO7rZzftrySdxwu7E6HQ3aKBnTz8mC4'","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-09T11:02:04.762669Z","iopub.execute_input":"2024-11-09T11:02:04.763027Z","iopub.status.idle":"2024-11-09T11:02:04.768912Z","shell.execute_reply.started":"2024-11-09T11:02:04.762982Z","shell.execute_reply":"2024-11-09T11:02:04.767774Z"}},"outputs":[],"execution_count":19},{"cell_type":"code","source":"from datasets import load_dataset, Dataset\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\nfrom transformers import BertTokenizer, BertForSequenceClassification, Trainer, TrainingArguments\nfrom torch.utils.data import Dataset, DataLoader\nimport torch\nimport numpy as np\nimport pandas as pd","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-09T11:02:04.771345Z","iopub.execute_input":"2024-11-09T11:02:04.771740Z","iopub.status.idle":"2024-11-09T11:02:04.782576Z","shell.execute_reply.started":"2024-11-09T11:02:04.771705Z","shell.execute_reply":"2024-11-09T11:02:04.781661Z"}},"outputs":[],"execution_count":20},{"cell_type":"code","source":"device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nprint(\"Using device:\", device)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-09T11:02:04.783725Z","iopub.execute_input":"2024-11-09T11:02:04.784051Z","iopub.status.idle":"2024-11-09T11:02:04.823516Z","shell.execute_reply.started":"2024-11-09T11:02:04.784016Z","shell.execute_reply":"2024-11-09T11:02:04.822553Z"}},"outputs":[{"name":"stdout","text":"Using device: cuda\n","output_type":"stream"}],"execution_count":21},{"cell_type":"code","source":"dataset = load_dataset(\"nguha/legalbench\", 'cuad_audit_rights')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-09T11:02:04.824688Z","iopub.execute_input":"2024-11-09T11:02:04.824992Z","iopub.status.idle":"2024-11-09T11:02:06.170756Z","shell.execute_reply.started":"2024-11-09T11:02:04.824959Z","shell.execute_reply":"2024-11-09T11:02:06.169770Z"}},"outputs":[],"execution_count":22},{"cell_type":"code","source":"dataset","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-09T11:02:06.172065Z","iopub.execute_input":"2024-11-09T11:02:06.172811Z","iopub.status.idle":"2024-11-09T11:02:06.179259Z","shell.execute_reply.started":"2024-11-09T11:02:06.172765Z","shell.execute_reply":"2024-11-09T11:02:06.178252Z"}},"outputs":[{"execution_count":23,"output_type":"execute_result","data":{"text/plain":"DatasetDict({\n    train: Dataset({\n        features: ['answer', 'index', 'text', 'document_name'],\n        num_rows: 6\n    })\n    test: Dataset({\n        features: ['answer', 'index', 'text', 'document_name'],\n        num_rows: 1216\n    })\n})"},"metadata":{}}],"execution_count":23},{"cell_type":"code","source":"# Convert to DataFrame for easier handling\ndf_train = pd.DataFrame(dataset['test'])\ndf_test = pd.DataFrame(dataset['train'])\n\n# Preprocess text\ndf_train['cleaned_text'] = df_train['text'].apply(lambda text: text.strip().lower())\ndf_test['cleaned_text'] = df_test['text'].apply(lambda text: text.strip().lower())\n\n#To split the data better\ndf_combined = pd.concat([df_train, df_test])\ndf_combined.drop(columns=['index'])\n\n# Shuffle the data\ndf_combined_shuffled = df_combined.sample(frac=1).reset_index(drop=True)\ndf_combined_shuffled.drop(columns=['index'])\n\n# Split the data into training, validation, and test sets\ntrain_data, test_data = train_test_split(df_combined_shuffled, test_size=0.2, stratify = df_combined_shuffled['answer'])\nval_data, test_data = train_test_split(test_data, test_size=0.4, stratify = test_data['answer'])\n\nprint(f\"Training set size: {train_data.shape}\")\nprint(f\"Validation set size: {val_data.shape}\")\nprint(f\"Test set size: {test_data.shape}\")\n     ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-09T11:02:06.180706Z","iopub.execute_input":"2024-11-09T11:02:06.181356Z","iopub.status.idle":"2024-11-09T11:02:06.274313Z","shell.execute_reply.started":"2024-11-09T11:02:06.181313Z","shell.execute_reply":"2024-11-09T11:02:06.273409Z"}},"outputs":[{"name":"stdout","text":"Training set size: (977, 5)\nValidation set size: (147, 5)\nTest set size: (98, 5)\n","output_type":"stream"}],"execution_count":24},{"cell_type":"code","source":"# Initialize the tokenizer and model\ntokenizer = BertTokenizer.from_pretrained('nlpaueb/legal-bert-base-uncased')\nmodel = BertForSequenceClassification.from_pretrained('nlpaueb/legal-bert-base-uncased', num_labels=2)\nmodel.to(device)\n\n# Tokenize the inputs\ntrain_encodings = tokenizer(train_data['cleaned_text'].tolist(), truncation=True, padding=True, max_length=512)\nval_encodings = tokenizer(val_data['cleaned_text'].tolist(), truncation=True, padding=True, max_length=512)\n\n# Convert labels to tensor\ntrain_labels = torch.tensor(train_data['answer'].apply(lambda x: 1 if x.lower() == \"yes\" else 0).tolist())\nval_labels = torch.tensor(val_data['answer'].apply(lambda x: 1 if x.lower() == \"yes\" else 0).tolist())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-09T11:02:06.275597Z","iopub.execute_input":"2024-11-09T11:02:06.276455Z","iopub.status.idle":"2024-11-09T11:02:09.615244Z","shell.execute_reply.started":"2024-11-09T11:02:06.276407Z","shell.execute_reply":"2024-11-09T11:02:09.614442Z"}},"outputs":[{"name":"stderr","text":"Some weights of BertForSequenceClassification were not initialized from the model checkpoint at nlpaueb/legal-bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"}],"execution_count":25},{"cell_type":"markdown","source":"# Finetuning Checkpoint","metadata":{}},{"cell_type":"code","source":"# Create dataset class\nclass LegalDataset(torch.utils.data.Dataset):\n    def __init__(self, encodings, labels):\n        self.encodings = encodings\n        self.labels = labels\n\n    def __getitem__(self, idx):\n        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n        item['labels'] = self.labels[idx]\n        return item\n\n    def __len__(self):\n        return len(self.labels)\n\n# Create datasets\ntrain_dataset = LegalDataset(train_encodings, train_labels)\nval_dataset = LegalDataset(val_encodings, val_labels)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-09T11:02:09.618478Z","iopub.execute_input":"2024-11-09T11:02:09.618801Z","iopub.status.idle":"2024-11-09T11:02:09.625756Z","shell.execute_reply.started":"2024-11-09T11:02:09.618767Z","shell.execute_reply":"2024-11-09T11:02:09.624867Z"}},"outputs":[],"execution_count":26},{"cell_type":"code","source":"def train_and_evaluate(train_texts, train_labels, val_texts, val_labels, model, tokenizer):\n\n    # Tokenize the inputs\n    train_encodings = tokenizer(train_texts.tolist(), truncation=True, padding=True, max_length=512)\n    val_encodings = tokenizer(val_texts.tolist(), truncation=True, padding=True, max_length=512)\n\n    # Convert labels to tensor\n    train_labels = torch.tensor(train_labels.apply(lambda x: 1 if x.lower() == \"yes\" else 0).tolist())\n    val_labels = torch.tensor(val_labels.apply(lambda x: 1 if x.lower() == \"yes\" else 0).tolist())\n\n    # Create datasets\n    train_dataset = LegalDataset(train_encodings, train_labels)\n    val_dataset = LegalDataset(val_encodings, val_labels)\n\n    training_args = TrainingArguments(\n        output_dir='./results',\n        num_train_epochs=3,\n        per_device_train_batch_size=4,\n        per_device_eval_batch_size=4,\n        warmup_steps=500,\n        weight_decay=0.01,\n        logging_dir='./logs',\n        logging_steps=10,\n        eval_strategy=\"epoch\"\n    )\n\n    trainer = Trainer(\n        model = model,\n        args = training_args,\n        train_dataset = train_dataset,\n        eval_dataset = val_dataset,\n    )\n\n    trainer.train()\n    predictions = trainer.predict(val_dataset)\n    preds = predictions.predictions.argmax(-1)\n    labels = predictions.label_ids\n\n    accuracy = accuracy_score(labels, preds)\n    precision = precision_score(labels, preds)\n    recall = recall_score(labels, preds)\n    f1 = f1_score(labels, preds)\n\n    return accuracy, precision, recall, f1","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-09T11:02:09.626786Z","iopub.execute_input":"2024-11-09T11:02:09.627087Z","iopub.status.idle":"2024-11-09T11:02:09.643268Z","shell.execute_reply.started":"2024-11-09T11:02:09.627053Z","shell.execute_reply":"2024-11-09T11:02:09.642347Z"}},"outputs":[],"execution_count":27},{"cell_type":"markdown","source":"# K -Fold Validation","metadata":{}},{"cell_type":"code","source":"kf = StratifiedKFold(n_splits=5)\naccuracies, precisions, recalls, f1s = [], [], [], []\ntexts = train_data['cleaned_text']\nlabels = train_data['answer']\ni=0\nfor train_index, val_index in kf.split(texts, labels):\n    train_texts = texts[texts.index.isin(train_index)]\n    val_texts = texts[texts.index.isin(val_index)]\n    train_labels = labels[labels.index.isin(train_index)]\n    val_labels = labels[labels.index.isin(val_index)]\n\n    #Initializing a new model\n    model = BertForSequenceClassification.from_pretrained('nlpaueb/legal-bert-base-uncased', num_labels=2)\n    tokenizer = BertTokenizer.from_pretrained('nlpaueb/legal-bert-base-uncased')\n    model.to(device)\n\n    accuracy, precision, recall, f1 = train_and_evaluate(train_texts, train_labels, val_texts, val_labels, model, tokenizer)\n\n    accuracies.append(accuracy)\n    precisions.append(precision)\n    recalls.append(recall)\n    f1s.append(f1)\n\n    model.save_pretrained('fine-tuned-legal-bert-fold'+str(i))\n    tokenizer.save_pretrained('fine-tuned-legal-bert-fold'+str(i))\n    i+=1\n\n# Print average metrics\nprint(f\"Average Accuracy: {sum(accuracies) / len(accuracies)}\")\nprint(f\"Average Precision: {sum(precisions) / len(precisions)}\")\nprint(f\"Average Recall: {sum(recalls) / len(recalls)}\")\nprint(f\"Average F1 Score: {sum(f1s) / len(f1s)}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-09T11:02:09.644363Z","iopub.execute_input":"2024-11-09T11:02:09.644675Z","iopub.status.idle":"2024-11-09T11:12:36.111192Z","shell.execute_reply.started":"2024-11-09T11:02:09.644643Z","shell.execute_reply":"2024-11-09T11:12:36.110266Z"}},"outputs":[{"name":"stderr","text":"Some weights of BertForSequenceClassification were not initialized from the model checkpoint at nlpaueb/legal-bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend. Please refer to https://wandb.me/wandb-core for more information.\n\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"  ········\n"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.011112818500000938, max=1.0…","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7d8661ecc3504c4f836d45c41a223ecd"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.18.3"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20241109_110233-w9lvqa7q</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/swrao21-pes-university/huggingface/runs/w9lvqa7q' target=\"_blank\">./results</a></strong> to <a href='https://wandb.ai/swrao21-pes-university/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/swrao21-pes-university/huggingface' target=\"_blank\">https://wandb.ai/swrao21-pes-university/huggingface</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/swrao21-pes-university/huggingface/runs/w9lvqa7q' target=\"_blank\">https://wandb.ai/swrao21-pes-university/huggingface/runs/w9lvqa7q</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='474' max='474' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [474/474 01:57, Epoch 3/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>0.126900</td>\n      <td>0.050131</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.000700</td>\n      <td>0.048007</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0.118000</td>\n      <td>0.123608</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"name":"stderr","text":"Some weights of BertForSequenceClassification were not initialized from the model checkpoint at nlpaueb/legal-bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='462' max='462' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [462/462 01:53, Epoch 3/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>0.258200</td>\n      <td>0.198906</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.130400</td>\n      <td>0.015291</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0.000200</td>\n      <td>0.041073</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"name":"stderr","text":"Some weights of BertForSequenceClassification were not initialized from the model checkpoint at nlpaueb/legal-bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='468' max='468' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [468/468 01:56, Epoch 3/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>0.198200</td>\n      <td>0.106642</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.000900</td>\n      <td>0.100620</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0.000300</td>\n      <td>0.106083</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"name":"stderr","text":"Some weights of BertForSequenceClassification were not initialized from the model checkpoint at nlpaueb/legal-bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='474' max='474' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [474/474 01:57, Epoch 3/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>0.173500</td>\n      <td>0.045540</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.000900</td>\n      <td>0.034061</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0.000200</td>\n      <td>0.000115</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"name":"stderr","text":"Some weights of BertForSequenceClassification were not initialized from the model checkpoint at nlpaueb/legal-bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='471' max='471' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [471/471 01:47, Epoch 3/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>0.234900</td>\n      <td>0.079451</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.001000</td>\n      <td>0.140555</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0.000200</td>\n      <td>0.004194</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"name":"stdout","text":"Average Accuracy: 0.9923131620053658\nAverage Precision: 0.9877628778203491\nAverage Recall: 0.9974999999999999\nAverage F1 Score: 0.9925855769916836\n","output_type":"stream"}],"execution_count":28},{"cell_type":"code","source":"# Define the test function\ndef test_model(test_texts, test_labels, model_path, tokenizer_path):\n    # Load the fine-tuned model and tokenizer\n    model = BertForSequenceClassification.from_pretrained(model_path)\n    tokenizer = BertTokenizer.from_pretrained(tokenizer_path)\n    model.to(device)\n\n    # Tokenize the test texts\n    test_encodings = tokenizer(test_texts.tolist(), truncation=True, padding=True, max_length=512)\n\n    # Convert labels to tensor\n    test_labels_tensor = torch.tensor(test_labels.apply(lambda x: 1 if x.lower() == \"yes\" else 0).tolist())\n\n    # Create a test dataset\n    test_dataset = LegalDataset(test_encodings, test_labels_tensor)\n\n    # Create a DataLoader for the test dataset\n    test_loader = DataLoader(test_dataset, batch_size=4, shuffle=False)\n\n    # Evaluate the model\n    model.eval()\n    preds = []\n    labels = []\n    with torch.no_grad():\n        for batch in test_loader:\n            input_ids = batch['input_ids'].to(device)\n            attention_mask = batch['attention_mask'].to(device)\n            labels.extend(batch['labels'].cpu().numpy())\n            outputs = model(input_ids, attention_mask=attention_mask)\n            preds.extend(torch.argmax(outputs.logits, dim=-1).cpu().numpy())\n\n    # Calculate metrics\n    accuracy = accuracy_score(labels, preds)\n    precision = precision_score(labels, preds)\n    recall = recall_score(labels, preds)\n    f1 = f1_score(labels, preds)\n\n    return accuracy, precision, recall, f1","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-09T11:12:36.112836Z","iopub.execute_input":"2024-11-09T11:12:36.113231Z","iopub.status.idle":"2024-11-09T11:12:36.124007Z","shell.execute_reply.started":"2024-11-09T11:12:36.113185Z","shell.execute_reply":"2024-11-09T11:12:36.123056Z"}},"outputs":[],"execution_count":29},{"cell_type":"code","source":"# Now, we will try loading the test data. \ntest_texts = test_data['cleaned_text']\ntest_labels = test_data['answer']\n\n# Iterate over the saved models and evaluate them\nfor i in range(5):  # I'm using 5 models here \n    model_path = f'fine-tuned-legal-bert-fold{i}'\n    tokenizer_path = f'fine-tuned-legal-bert-fold{i}'\n\n    accuracy, precision, recall, f1 = test_model(test_texts, test_labels, model_path, tokenizer_path)\n    print(f\"Model {i} - Accuracy: {accuracy}, Precision: {precision}, Recall: {recall}, F1 Score: {f1}\")\n\naccuracy, precision, recall, f1 = test_model(test_texts, test_labels,'nlpaueb/legal-bert-base-uncased', 'nlpaueb/legal-bert-base-uncased')\nprint(f\"Model (untrained Legal-BERT) - Accuracy: {accuracy}, Precision: {precision}, Recall: {recall}, F1 Score: {f1}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-09T11:12:36.125132Z","iopub.execute_input":"2024-11-09T11:12:36.125438Z","iopub.status.idle":"2024-11-09T11:12:48.926616Z","shell.execute_reply.started":"2024-11-09T11:12:36.125381Z","shell.execute_reply":"2024-11-09T11:12:48.925516Z"}},"outputs":[{"name":"stdout","text":"Model 0 - Accuracy: 0.9795918367346939, Precision: 0.9607843137254902, Recall: 1.0, F1 Score: 0.98\nModel 1 - Accuracy: 0.9795918367346939, Precision: 0.9607843137254902, Recall: 1.0, F1 Score: 0.98\nModel 2 - Accuracy: 0.9795918367346939, Precision: 0.9607843137254902, Recall: 1.0, F1 Score: 0.98\nModel 3 - Accuracy: 0.9795918367346939, Precision: 0.9607843137254902, Recall: 1.0, F1 Score: 0.98\nModel 4 - Accuracy: 0.9897959183673469, Precision: 0.98, Recall: 1.0, F1 Score: 0.98989898989899\n","output_type":"stream"},{"name":"stderr","text":"Some weights of BertForSequenceClassification were not initialized from the model checkpoint at nlpaueb/legal-bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"name":"stdout","text":"Model (untrained Legal-BERT) - Accuracy: 0.45918367346938777, Precision: 0.3333333333333333, Recall: 0.08163265306122448, F1 Score: 0.13114754098360654\n","output_type":"stream"}],"execution_count":30},{"cell_type":"code","source":"import os\n\n# Directory to save models\nsave_dir = '/kaggle/working/fine-tuned-legal-bert-5folds'\nos.makedirs(save_dir, exist_ok=True)\n\nfor i in range(5):  # Since we have five models. \n    model_path = f'fine-tuned-legal-bert-fold{i}'\n    tokenizer_path = f'fine-tuned-legal-bert-fold{i}'\n\n    model.save_pretrained(os.path.join(save_dir, model_path))\n    tokenizer.save_pretrained(os.path.join(save_dir, tokenizer_path))\n\nprint(f\"Models saved to {save_dir}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-09T11:12:48.927933Z","iopub.execute_input":"2024-11-09T11:12:48.928306Z","iopub.status.idle":"2024-11-09T11:12:52.532691Z","shell.execute_reply.started":"2024-11-09T11:12:48.928269Z","shell.execute_reply":"2024-11-09T11:12:52.531726Z"}},"outputs":[{"name":"stdout","text":"Models saved to /kaggle/working/fine-tuned-legal-bert-5folds\n","output_type":"stream"}],"execution_count":31},{"cell_type":"code","source":"from transformers import BertForSequenceClassification, BertTokenizer\n\n# Path to the dataset on Kaggle\nmodel_path = \"/kaggle/working/fine-tuned-legal-bert-fold2\"\n\n# Load model and tokenizer\nmodel = BertForSequenceClassification.from_pretrained(model_path)\ntokenizer = BertTokenizer.from_pretrained(model_path)\n\n# Move model to the specified device\ndevice = \"cuda\" if torch.cuda.is_available() else \"cpu\"\nmodel.to(device)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-09T11:12:52.534309Z","iopub.execute_input":"2024-11-09T11:12:52.534729Z","iopub.status.idle":"2024-11-09T11:12:52.825436Z","shell.execute_reply.started":"2024-11-09T11:12:52.534684Z","shell.execute_reply":"2024-11-09T11:12:52.824445Z"}},"outputs":[{"execution_count":32,"output_type":"execute_result","data":{"text/plain":"BertForSequenceClassification(\n  (bert): BertModel(\n    (embeddings): BertEmbeddings(\n      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n      (position_embeddings): Embedding(512, 768)\n      (token_type_embeddings): Embedding(2, 768)\n      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n      (dropout): Dropout(p=0.1, inplace=False)\n    )\n    (encoder): BertEncoder(\n      (layer): ModuleList(\n        (0-11): 12 x BertLayer(\n          (attention): BertAttention(\n            (self): BertSdpaSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n      )\n    )\n    (pooler): BertPooler(\n      (dense): Linear(in_features=768, out_features=768, bias=True)\n      (activation): Tanh()\n    )\n  )\n  (dropout): Dropout(p=0.1, inplace=False)\n  (classifier): Linear(in_features=768, out_features=2, bias=True)\n)"},"metadata":{}}],"execution_count":32},{"cell_type":"code","source":"# Load model\nmodel = BertForSequenceClassification.from_pretrained(\"/kaggle/working/fine-tuned-legal-bert-fold0\")\ntokenizer = BertTokenizer.from_pretrained(\"/kaggle/working/fine-tuned-legal-bert-fold0\")\nmodel.to(device)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-09T11:12:52.826731Z","iopub.execute_input":"2024-11-09T11:12:52.827143Z","iopub.status.idle":"2024-11-09T11:12:54.770402Z","shell.execute_reply.started":"2024-11-09T11:12:52.827096Z","shell.execute_reply":"2024-11-09T11:12:54.769468Z"}},"outputs":[{"execution_count":33,"output_type":"execute_result","data":{"text/plain":"BertForSequenceClassification(\n  (bert): BertModel(\n    (embeddings): BertEmbeddings(\n      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n      (position_embeddings): Embedding(512, 768)\n      (token_type_embeddings): Embedding(2, 768)\n      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n      (dropout): Dropout(p=0.1, inplace=False)\n    )\n    (encoder): BertEncoder(\n      (layer): ModuleList(\n        (0-11): 12 x BertLayer(\n          (attention): BertAttention(\n            (self): BertSdpaSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n      )\n    )\n    (pooler): BertPooler(\n      (dense): Linear(in_features=768, out_features=768, bias=True)\n      (activation): Tanh()\n    )\n  )\n  (dropout): Dropout(p=0.1, inplace=False)\n  (classifier): Linear(in_features=768, out_features=2, bias=True)\n)"},"metadata":{}}],"execution_count":33},{"cell_type":"code","source":"# Function for classification using Legal-BERT\ndef classify_clause_legal_bert(text):\n    inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, padding=True, max_length=512).to(device)\n    outputs = model(**inputs)\n    predictions = torch.argmax(outputs.logits, dim=-1)\n    return predictions.item()\n\ntest_clause= \"The Recipient shall not advertise or otherwise make public the fact that it has a confidential relationship with UNHCR nor shall the Recipient in any manner whatsoever use the name emblem or official seal of the United Nations or UNHCR or any abbreviation of the name of the United Nations or UNHCR in connection with its business or otherwise\"\n\n# Get the combined result\nresponse = classify_clause_legal_bert(test_clause)\n\n# Print the combined result\nprint(response)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-09T11:12:54.771453Z","iopub.execute_input":"2024-11-09T11:12:54.771730Z","iopub.status.idle":"2024-11-09T11:12:54.891672Z","shell.execute_reply.started":"2024-11-09T11:12:54.771700Z","shell.execute_reply":"2024-11-09T11:12:54.890696Z"}},"outputs":[{"name":"stdout","text":"0\n","output_type":"stream"}],"execution_count":34},{"cell_type":"markdown","source":"# Risk Analysis ","metadata":{}},{"cell_type":"code","source":"import os\nimport google.generativeai as genai\n\ngenai.configure(api_key=os.environ['GOOGLE_API_KEY'])\n\n# Create the model\ngeneration_config = {\n  \"temperature\": 1,\n  \"top_p\": 0.95,\n  \"top_k\": 40,\n  \"max_output_tokens\": 2000,\n  \"response_mime_type\": \"text/plain\",\n}\n\nmodel = genai.GenerativeModel(\n  model_name=\"gemini-1.5-flash\",\n  generation_config=generation_config,\n)\n\nchat_session = model.start_chat(\n  history=[]\n)\n\ndef run_riskAnalysis(clause):\n    risk_template = \"You are a legal advisor. Identify any definite risks in the clauses given to you. Mention that there are none if there are no risks. \"\n    response = chat_session.send_message(f\"{risk_template}\\n\\n{clause}\")\n    return response.text\n\n# Accept input from the user for the clause\ntest_clause = input(\"Enter the clause you would like to analyze for risks: \")\n\n# Get the combined result\nresponse = run_riskAnalysis(test_clause)\n\n# Print the combined result along with the sentences that lead to that conclusion\nprint(response)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-09T11:12:54.893141Z","iopub.execute_input":"2024-11-09T11:12:54.893459Z","iopub.status.idle":"2024-11-09T11:14:56.059335Z","shell.execute_reply.started":"2024-11-09T11:12:54.893420Z","shell.execute_reply":"2024-11-09T11:14:56.058350Z"}},"outputs":[{"output_type":"stream","name":"stdin","text":"Enter the clause you would like to analyze for risks:  The Recipient shall not be precluded from disclosing the Confidential Information that is (i) obtained by the Recipient without restriction from a third party who is not in breach of any obligation as to confidentiality to the owner of such Confidential Information or any other person, or\n"},{"name":"stdout","text":"The clause you provided presents several potential risks:\n\n**1. Ambiguity of \"obtained without restriction\":**\n\n* **Defining \"restriction\":**  What constitutes a \"restriction\" on disclosure is unclear.  Is it a formal contract, a verbal agreement, or even an understanding between parties? This ambiguity could lead to disputes about whether information was truly \"obtained without restriction.\"\n* **Publicly available information:** The clause doesn't explicitly address information that is publicly available.  If information is publicly available, it is generally not considered confidential. This lack of clarity could lead to the Recipient claiming they obtained the information publicly, even if it was shared in a confidential setting.\n\n**2. Reliance on third-party obligations:**\n\n* **Due diligence on third party:** The Recipient's ability to rely on a third party's non-breach of confidentiality is problematic. The Recipient bears the burden of ensuring the third party is not in breach. This requires due diligence on the Recipient's part to investigate the third party's obligations and ensure they are not violating any confidentiality agreements.\n* **Shifting burden of proof:** The clause places the burden of proof on the owner of the Confidential Information to prove the third party is in breach of a confidentiality obligation. This shifts the burden of proof away from the Recipient and could make it difficult for the owner to enforce their rights.\n\n**3. Lack of clarity on \"other person\":**\n\n* **Broad scope:** The clause mentions \"any other person\" without further defining who this refers to. This could be interpreted very broadly, making it difficult to determine what information the Recipient can disclose.\n\n**Overall:** This clause is overly broad and ambiguous, creating significant risks for the owner of the Confidential Information. \n\n**Recommendations:**\n\n* **Define \"restriction\" specifically:** Clearly outline what constitutes a \"restriction\" on disclosure, for example, by referencing written agreements, verbal agreements with specific terms, or other legal obligations. \n* **Address publicly available information:** Explicitly state that the Recipient is prohibited from disclosing information that is publicly available, even if obtained from a third party.\n* **Place the burden on the Recipient:** Require the Recipient to demonstrate that the third party is not in breach of a confidentiality obligation.\n* **Define \"other person\":** Specify who the \"other person\" refers to, for example, by limiting it to specific categories of individuals or entities.\n\nBy addressing these ambiguities and potential risks, the clause can be made more clear and enforceable, providing greater protection for the owner of the Confidential Information. \n\n","output_type":"stream"}],"execution_count":35},{"cell_type":"code","source":"import os\nimport google.generativeai as genai\n\n# Configure the API key\ngenai.configure(api_key=os.environ['GOOGLE_API_KEY'])\n\n# Create the model with generation configuration\ngeneration_config = {\n  \"temperature\": 1,\n  \"top_p\": 0.95,\n  \"top_k\": 40,\n  \"max_output_tokens\": 2000,\n  \"response_mime_type\": \"text/plain\",\n}\n\nmodel = genai.GenerativeModel(\n  model_name=\"gemini-1.5-flash\",\n  generation_config=generation_config,\n)\n\nchat_session = model.start_chat(\n  history=[]\n)\n\ndef run_gemini_integration(classification_label, risk_analysis, clause):\n    # Create the prompt based on classification and risks provided\n    prompt = (\n        f\"Here is a contract clause that has been classified as '{classification_label}'. \"\n        f\"Explain what that means:\\n\\n'{clause}'\\n\\n\"\n        f\"The potential risks identified in this clause are:\\n{risk_analysis}\\n\\n\"\n    )\n\n    # Send message to chat session\n    response = chat_session.send_message(\n        \"You are a legal advisor. Please provide an integrated, cohesive explanation of this clause, \"\n        \"its classification, and the identified risks. Provide the response in the following template:\\n\\n\" + prompt\n    )\n    return response.text\n\n# Sample inputs\nclassification_label = \"High Liability\"\nrisk_analysis = \"This clause may expose the company to significant legal liability due to the lack of limitation on indemnification.\"\nclause = \"The supplier agrees to indemnify and hold harmless the purchaser against any and all claims, damages, and expenses arising from the performance of this agreement.\"\n\n# Get the combined result\nresponse = run_gemini_integration(classification_label, risk_analysis, clause)\n\n# Print the combined result\nprint(response)\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-09T11:33:46.947541Z","iopub.execute_input":"2024-11-09T11:33:46.948286Z","iopub.status.idle":"2024-11-09T11:33:49.620172Z","shell.execute_reply.started":"2024-11-09T11:33:46.948244Z","shell.execute_reply":"2024-11-09T11:33:49.619256Z"}},"outputs":[{"name":"stdout","text":"## Contract Clause Analysis: \n\n**Clause:** \"The supplier agrees to indemnify and hold harmless the purchaser against any and all claims, damages, and expenses arising from the performance of this agreement.\"\n\n**Classification:** **High Liability**\n\n**Explanation:** This clause, classified as \"High Liability,\" is a broad indemnity provision. It obligates the supplier to protect the purchaser from any and all financial consequences stemming from the agreement's execution. This means the supplier is responsible for covering:\n\n* **Claims:**  Any legal action brought against the purchaser related to the agreement.\n* **Damages:** Financial losses incurred by the purchaser due to the supplier's actions or omissions.\n* **Expenses:**  Costs incurred by the purchaser in defending against claims or lawsuits. \n\n**Potential Risks Identified:**\n\nThis clause exposes the company to significant legal liability due to the lack of limitation on indemnification. Here's why:\n\n* **Unlimited Scope:** The clause lacks any specific limitations on the types of claims, damages, or expenses the supplier is responsible for. This could lead to the supplier being held liable for events completely outside their control or for actions by the purchaser. \n* **Potential for Significant Financial Burden:** The supplier could face significant financial burdens, particularly if the purchaser is negligent or their actions cause a large-scale problem. \n* **Unforeseen Consequences:**  The broad nature of the clause could lead to unforeseen consequences and unexpected liabilities. The supplier may be held liable for events that were not contemplated during the negotiation process.\n\n**Recommendations:**\n\n* **Negotiate Limitations:** The supplier should actively negotiate for limitations to the scope of the indemnity. This could include specific exclusions for certain types of claims or damages, limitations on the amount of liability, or a requirement that the purchaser take reasonable steps to mitigate their own risk.\n* **Insurance Coverage:** The supplier should consider securing appropriate insurance coverage to protect themselves against potential liabilities arising from the indemnity clause. \n* **Clearer Definitions:** The clause should include clear definitions of terms like \"claims,\" \"damages,\" and \"expenses\" to avoid ambiguity. \n* **Specific Examples:** Include specific examples of the types of events the supplier is expected to indemnify the purchaser for to ensure both parties understand the scope of the agreement.\n\n**Overall:** This clause places a significant burden on the supplier and requires careful review and negotiation to ensure it is reasonable and does not expose the company to excessive risk. \n\n","output_type":"stream"}],"execution_count":59},{"cell_type":"code","source":"import os\nimport google.generativeai as genai\nfrom transformers import BertForSequenceClassification, BertTokenizer\nimport torch\n\n# Load Legal-BERT model and tokenizer\nmodel_path = \"/kaggle/working/fine-tuned-legal-bert-fold0\"\nmodel = BertForSequenceClassification.from_pretrained(model_path)\ntokenizer = BertTokenizer.from_pretrained(model_path)\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel.to(device)\n\n# Configure API for generative AI\ngenai.configure(api_key=os.environ['GOOGLE_API_KEY'])\n\n# Create generative model configuration\ngeneration_config = {\n  \"temperature\": 1,\n  \"top_p\": 0.95,\n  \"top_k\": 40,\n  \"max_output_tokens\": 8192,\n  \"response_mime_type\": \"text/plain\",\n}\n\ngenerative_model = genai.GenerativeModel(\n  model_name=\"gemini-1.5-flash\",\n  generation_config=generation_config,\n)\n\nchat_session = generative_model.start_chat(history=[])\n\n# Function to classify clause using Legal-BERT\ndef classify_clause_legal_bert(clause):\n    inputs = tokenizer(clause, return_tensors=\"pt\").to(device)\n    outputs = model(**inputs)\n    logits = outputs.logits\n    prediction = torch.argmax(logits, dim=-1).item()\n    return prediction\n\n# Function to analyze risks using generative AI\ndef run_riskAnalysis(clause):\n    risk_template = \"You are a legal advisor. Identify any definite risks in the clauses given to you. Mention that there are none if there are no risks.\"\n    response = chat_session.send_message(f\"{risk_template}\\n\\n{clause}\")\n    return response.text\n\n# Function to run prompt using Gemini model\ndef run_gemini_integration(classification_label, risk_analysis, clause):\n    prompt = (\n        f\"Here is a contract clause that has been classified as '{classification_label}.Name what type of clause it is and explain what this clause means for the user.':\\n\\n\"\n        f\"'{clause}'\\n\\n\"\n        f\"The potential risks identified in this clause are:\\n{risk_analysis}. Give the exact lines that explain this risk. \\n\\n\"\n    )\n\n    response = chat_session.send_message(\n        \"You are a legal advisor. First, mention the legal name of the claus and explain how it works. Please provide an integrated, cohesive explanation of this clause, \"\n        \"its classification, and the identified risks. Don't give the recommendations to mitigate the clause. Provide the response in the following template:\\n\\n\" + prompt\n    )\n    return response.text\n\n# Combined function to classify and analyze a clause\ndef classify_and_analyze_clause(clause):\n    classification_result = classify_clause_legal_bert(clause)\n    classification_label = \"Audit Clause\" if classification_result == 1 else \"Not an Audit Clause\"\n    risk_analysis = run_riskAnalysis(clause)\n    integrated_response = run_gemini_integration(classification_label, risk_analysis, clause)\n    return integrated_response\n\n# Test with a sample clause\ntest_clause = input(\"Please enter a contract clause to analyze: \")\n\n# Get the result\nresponse = classify_and_analyze_clause(test_clause)\n\n# Print the result\nprint(response)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-09T12:33:18.993336Z","iopub.execute_input":"2024-11-09T12:33:18.994022Z","iopub.status.idle":"2024-11-09T12:33:24.083187Z","shell.execute_reply.started":"2024-11-09T12:33:18.993984Z","shell.execute_reply":"2024-11-09T12:33:24.082206Z"}},"outputs":[{"output_type":"stream","name":"stdin","text":"Please enter a contract clause to analyze:  \n"},{"name":"stdout","text":"Please provide me with the clause you want me to review. I need the specific text of the clause to identify any potential risks. Once you provide the clause, I will:\n\n1. **Classify the clause:** I will determine the type of clause (e.g., Audit Clause, Termination Clause, Indemnification Clause).\n2. **Explain its meaning:** I will provide a clear and concise explanation of what the clause means for the user in the context of the agreement.\n3. **Identify potential risks:** I will analyze the clause for any potential legal issues, such as:\n    * **Ambiguity:** Unclear language that could be interpreted in multiple ways, leading to disputes.\n    * **Unenforceability:** Clauses that violate laws or established legal principles, making them unenforceable.\n    * **Liability:** Provisions that could expose a party to financial or other legal consequences.\n    * **Breach of contract:** Clauses that create grounds for one party to terminate the agreement or seek damages.\n    * **Misrepresentation:** Clauses that could be considered misleading or deceptive.\n4. **Highlight specific lines:** I will quote the exact lines from the clause that illustrate the identified risks.\n\nI look forward to helping you understand the potential risks associated with the clause you provide. \n\n","output_type":"stream"}],"execution_count":82}]}